{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from functools import wraps\n",
    "from requests import ConnectionError\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from hackernews import HackerNews, InvalidItemID\n",
    "from readability import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hacker News API raise ConnectionError very often. This code fix it.\n",
    "\n",
    "def decorate_all_methods(decorator):\n",
    "    @wraps(decorator)\n",
    "    def decorate(cls):\n",
    "        for attr_name in cls.__dict__:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if callable(attr):\n",
    "                setattr(cls, attr_name, decorator(attr))\n",
    "        return cls\n",
    "    return decorate\n",
    "\n",
    "\n",
    "def try_to_reconnect(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        while True:\n",
    "            try:\n",
    "                res = func(*args, **kwargs)\n",
    "            except ConnectionError:\n",
    "                continue\n",
    "            return res\n",
    "    return wrapper\n",
    "\n",
    "HackerNews = decorate_all_methods(try_to_reconnect)(HackerNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdir_if_not_exists(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "class HNUser:\n",
    "    hn_api = HackerNews()\n",
    "        \n",
    "        \n",
    "class ExtendedItem(HNUser):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all item's attrs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        self.__dict__.update(item.__dict__)\n",
    "        self.kids = self.kids if self.kids is not None else []\n",
    "        \n",
    "\n",
    "class Comment(ExtendedItem):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all ExtendedItem's attrs\n",
    "        \n",
    "    Attributes:\n",
    "        * subcomments (list): of Comments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        super().__init__(item)\n",
    "        self.load_subcomments()\n",
    "    \n",
    "    def load_subcomments(self):\n",
    "        self.subcomments = []\n",
    "        for comment_id in self.kids:\n",
    "            try:\n",
    "                item_api = self.hn_api.get_item(comment_id)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            self.subcomments.append(Comment(item_api))\n",
    "        \n",
    "        \n",
    "class Post(ExtendedItem):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all ExtendedItem's attrs\n",
    "        \n",
    "    Attributes:\n",
    "        * comments (list): of Comments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        super().__init__(item)\n",
    "        self.load_comments()\n",
    "    \n",
    "    def load_comments(self):\n",
    "        self.comments = []\n",
    "        for comment_id in self.kids:\n",
    "            try:\n",
    "                item_api = self.hn_api.get_item(comment_id)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            self.comments.append(Comment(item_api))\n",
    "            \n",
    "    \n",
    "\n",
    "class HNData(HNUser):\n",
    "    \"\"\"\n",
    "    HackerNews downloader\n",
    "    \n",
    "    Notes:\n",
    "        Uses unofficial python HN python wrapper (https://github.com/HackerNews/API)\n",
    "    \n",
    "    Args:\n",
    "        folder: for data storage\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder=DATA_FOLDER):\n",
    "        self.folder = folder\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.get_files_number()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.iterate_all_posts()\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        key = str(key)\n",
    "        return self.load_post(key)\n",
    "        \n",
    "    def download_last(self, last_days=182, types=('story', ), start_from_id=None):\n",
    "        \"\"\"\n",
    "        Download all needed data from HackerNews\n",
    "\n",
    "        Args:\n",
    "            types (iterable): list of types (“job”, “story”, “comment”, “poll”, “pollopt”).\n",
    "        \"\"\"\n",
    "        \n",
    "        start_from_id = self.hn_api.get_max_item() if start_from_id is None else start_from_id\n",
    "        saved = 0\n",
    "        stat = Counter()\n",
    "        \n",
    "        stop_cycle = False\n",
    "        \n",
    "        last_date = datetime.now()\n",
    "            \n",
    "        for item_number in range(start_from_id, 1, -1):\n",
    "            clear_output()\n",
    "            print('{}/{} watched | {} saved\\nlast_date: {}'.format(\n",
    "                item_number, start_from_id, saved,\n",
    "                last_date\n",
    "            ))\n",
    "            print(stat)\n",
    "            \n",
    "            try:\n",
    "                api_item = self.hn_api.get_item(item_number)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            \n",
    "            item = ExtendedItem(api_item)\n",
    "                \n",
    "            stat[item.item_type] += 1\n",
    "\n",
    "            if self.type_from_list(item, types):\n",
    "                if self.is_last_n_days(item, last_days):\n",
    "                    post = Post(item)\n",
    "                    self.save_post(post)\n",
    "                    saved += 1\n",
    "                    last_date = post.submission_time\n",
    "                else:\n",
    "                    stop_cycle = True\n",
    "            \n",
    "            if stop_cycle:\n",
    "                break\n",
    "        \n",
    "        print('Done!')\n",
    "    \n",
    "    def add_external_to_posts(self, start_from=None):\n",
    "        for number, post in enumerate(self.iterate_all_posts()):\n",
    "            clear_output()\n",
    "            print('{}/{}'.format(number, self.get_files_number()), post.item_id)\n",
    "            if start_from is None:\n",
    "                if post.url is None:\n",
    "                    post.external = None\n",
    "                else:\n",
    "                    try:\n",
    "                        response = requests.get(post.url, timeout=5)\n",
    "                        doc = Document(response.text)\n",
    "                        post.external = doc.summary()\n",
    "                    except:\n",
    "                        post.external = None\n",
    "                self.save_post(post)\n",
    "            elif str(post.item_id) == str(start_from):\n",
    "                start_from = None\n",
    "        \n",
    "        print('Done!')\n",
    "    \n",
    "    def save_post(self, post):\n",
    "        with open(os.path.join(self.folder, str(post.item_id)), 'wb') as file:\n",
    "            pickle.dump(post, file)\n",
    "            \n",
    "    def load_post(self, file):\n",
    "        with open(os.path.join(self.folder, file), 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    \n",
    "    def get_files(self):\n",
    "        return sorted(os.listdir(self.folder))\n",
    "    \n",
    "    def get_files_number(self):\n",
    "        return len(self.get_files())\n",
    "            \n",
    "    def iterate_all_posts(self):\n",
    "        for file in self.get_files():\n",
    "            yield self.load_post(file)\n",
    "            \n",
    "    def is_last_n_days(self, item, last_days, from_time=datetime.now()):\n",
    "        return item.submission_time > from_time - timedelta(days=182)\n",
    "    \n",
    "    def type_from_list(self, item, types):\n",
    "        return item.item_type in types\n",
    "    \n",
    "    def post_mentions_brand(self, post):\n",
    "        \"\"\"\n",
    "        Searches for a match in post's text or external.\n",
    "\n",
    "        Args: \n",
    "            post: a Post object, to search matches in.\n",
    "            \n",
    "        Returns:\n",
    "            bool: true if found a match.\n",
    "        \"\"\"\n",
    "        \n",
    "        text = \"\"\n",
    "        if post.text is not None:\n",
    "            text += post.text\n",
    "        if post.external is not None:\n",
    "            text += ' ' + post.external\n",
    "        return self.brand_regexp.search(text) is not None\n",
    "\n",
    "    def filter_posts_with_brand(self, brand):\n",
    "        \"\"\"\n",
    "        Filters texts with brand mentions.\n",
    "        \n",
    "        Args:\n",
    "            brand (str): name of brand.\n",
    "            \n",
    "        Returns:\n",
    "            generator: filtered posts\n",
    "        \"\"\"\n",
    "        \n",
    "        self.brand_regexp = re.compile(brand, re.IGNORECASE)\n",
    "        \n",
    "        return filter(self.post_mentions_brand, self.iterate_all_posts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hn_data = HNData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15361009/15367531 watched | 876 saved\n",
      "last_date: 2017-09-29 00:46:04\n",
      "Counter({'comment': 5644, 'story': 876, 'job': 2})\n"
     ]
    }
   ],
   "source": [
    "hn_data.download_last(start_from_id=15361009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/5727 15361404\n"
     ]
    }
   ],
   "source": [
    "hn_data.add_external_to_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n"
     ]
    }
   ],
   "source": [
    "amazon_posts = list(hn_data.filter_posts_with_brand('amazon'))\n",
    "print(len(amazon_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Размер корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazon_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_counter = Counter()\n",
    "for post in amazon_posts:\n",
    "    if post.url is not None:\n",
    "        domain = urlparse(post.url).netloc\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "    else: \n",
    "        domain = 'news.ycombinator.com'\n",
    "    domain_counter[domain] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('medium.com', 21),\n",
       " ('news.ycombinator.com', 16),\n",
       " ('techcrunch.com', 10),\n",
       " ('nytimes.com', 8),\n",
       " ('github.com', 7),\n",
       " ('theatlantic.com', 7),\n",
       " ('hackernoon.com', 7),\n",
       " ('qz.com', 6),\n",
       " ('viralgamesnews.com', 6),\n",
       " ('businessinsider.com', 6),\n",
       " ('wired.co.uk', 5),\n",
       " ('aws.amazon.com', 5),\n",
       " ('bloomberg.com', 5),\n",
       " ('economist.com', 4),\n",
       " ('bbc.com', 4),\n",
       " ('blog.clubhouse.io', 4),\n",
       " ('newyorker.com', 4),\n",
       " ('washingtonpost.com', 4),\n",
       " ('bbc.co.uk', 4),\n",
       " ('vanityfair.com', 4)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
