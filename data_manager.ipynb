{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from functools import wraps\n",
    "from requests import ConnectionError\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from hackernews import HackerNews, InvalidItemID\n",
    "from readability import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hacker News API raise ConnectionError very often. This code fix it.\n",
    "\n",
    "def decorate_all_methods(decorator):\n",
    "    @wraps(decorator)\n",
    "    def decorate(cls):\n",
    "        for attr_name in cls.__dict__:\n",
    "            attr = getattr(cls, attr_name)\n",
    "            if callable(attr):\n",
    "                setattr(cls, attr_name, decorator(attr))\n",
    "        return cls\n",
    "    return decorate\n",
    "\n",
    "\n",
    "def try_to_reconnect(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        while True:\n",
    "            try:\n",
    "                res = func(*args, **kwargs)\n",
    "            except ConnectionError:\n",
    "                continue\n",
    "            return res\n",
    "    return wrapper\n",
    "\n",
    "HackerNews = decorate_all_methods(try_to_reconnect)(HackerNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mkdir_if_not_exists(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "class HNUser:\n",
    "    hn_api = HackerNews()\n",
    "        \n",
    "        \n",
    "class ExtendedItem(HNUser):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all item's attrs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        self.__dict__.update(item.__dict__)\n",
    "        self.kids = self.kids if self.kids is not None else []\n",
    "        \n",
    "\n",
    "class Comment(ExtendedItem):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all ExtendedItem's attrs\n",
    "        \n",
    "    Attributes:\n",
    "        * subcomments (list): of Comments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        super().__init__(item)\n",
    "        self.load_subcomments()\n",
    "    \n",
    "    def load_subcomments(self):\n",
    "        self.subcomments = []\n",
    "        for comment_id in self.kids:\n",
    "            try:\n",
    "                item_api = self.hn_api.get_item(comment_id)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            self.subcomments.append(Comment(item_api))\n",
    "        \n",
    "        \n",
    "class Post(ExtendedItem):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Has all ExtendedItem's attrs\n",
    "        \n",
    "    Attributes:\n",
    "        * comments (list): of Comments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, item):\n",
    "        super().__init__(item)\n",
    "        self.load_comments()\n",
    "    \n",
    "    def load_comments(self):\n",
    "        self.comments = []\n",
    "        for comment_id in self.kids:\n",
    "            try:\n",
    "                item_api = self.hn_api.get_item(comment_id)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            self.comments.append(Comment(item_api))\n",
    "            \n",
    "    \n",
    "\n",
    "class HNData(HNUser):\n",
    "    \"\"\"\n",
    "    HackerNews downloader\n",
    "    \n",
    "    Notes:\n",
    "        Uses unofficial python HN python wrapper (https://github.com/HackerNews/API)\n",
    "    \n",
    "    Args:\n",
    "        folder: for data storage\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder=DATA_FOLDER):\n",
    "        self.folder = folder\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.get_files_number()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.iterate_all_posts()\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        key = str(key)\n",
    "        return self.load_post(key)\n",
    "        \n",
    "    def download_last(self, last_days=182, types=('story', ), start_from_id=None):\n",
    "        \"\"\"\n",
    "        Download all needed data from HackerNews\n",
    "\n",
    "        Args:\n",
    "            types (iterable): list of types (“job”, “story”, “comment”, “poll”, “pollopt”).\n",
    "        \"\"\"\n",
    "        \n",
    "        start_from_id = self.hn_api.get_max_item() if start_from_id is None else start_from_id\n",
    "        saved = 0\n",
    "        stat = Counter()\n",
    "        \n",
    "        stop_cycle = False\n",
    "        \n",
    "        last_date = datetime.now()\n",
    "            \n",
    "        for item_number in range(start_from_id, 1, -1):\n",
    "            clear_output()\n",
    "            print('{}/{} watched | {} saved\\nlast_date: {}'.format(\n",
    "                item_number, start_from_id, saved,\n",
    "                last_date\n",
    "            ))\n",
    "            print(stat)\n",
    "            \n",
    "            try:\n",
    "                api_item = self.hn_api.get_item(item_number)\n",
    "            except InvalidItemID:\n",
    "                continue\n",
    "            \n",
    "            item = ExtendedItem(api_item)\n",
    "                \n",
    "            stat[item.item_type] += 1\n",
    "\n",
    "            if self.type_from_list(item, types):\n",
    "                if self.is_last_n_days(item, last_days):\n",
    "                    post = Post(item)\n",
    "                    self.save_post(post)\n",
    "                    saved += 1\n",
    "                    last_date = post.submission_time\n",
    "                else:\n",
    "                    stop_cycle = True\n",
    "            \n",
    "            if stop_cycle:\n",
    "                break\n",
    "        \n",
    "        print('Done!')\n",
    "    \n",
    "    def add_external_to_posts(self, start_from=None):\n",
    "        for number, post in enumerate(self.iterate_all_posts()):\n",
    "            clear_output()\n",
    "            print('{}/{}'.format(number, self.get_files_number()), post.item_id)\n",
    "            if start_from is None:\n",
    "                if post.url is None:\n",
    "                    post.external = None\n",
    "                else:\n",
    "                    try:\n",
    "                        response = requests.get(post.url, timeout=5)\n",
    "                        doc = Document(response.text)\n",
    "                        post.external = doc.summary()\n",
    "                    except:\n",
    "                        post.external = None\n",
    "                self.save_post(post)\n",
    "            elif str(post.item_id) == str(start_from):\n",
    "                start_from = None\n",
    "        \n",
    "        print('Done!')\n",
    "    \n",
    "    def save_post(self, post):\n",
    "        with open(os.path.join(self.folder, str(post.item_id)), 'wb') as file:\n",
    "            pickle.dump(post, file)\n",
    "            \n",
    "    def load_post(self, file):\n",
    "        with open(os.path.join(self.folder, file), 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    \n",
    "    def get_files(self):\n",
    "        return sorted(os.listdir(self.folder))\n",
    "    \n",
    "    def get_files_number(self):\n",
    "        return len(self.get_files())\n",
    "            \n",
    "    def iterate_all_posts(self):\n",
    "        for file in self.get_files():\n",
    "            yield self.load_post(file)\n",
    "            \n",
    "    def is_last_n_days(self, item, last_days, from_time=datetime.now()):\n",
    "        return item.submission_time > from_time - timedelta(days=182)\n",
    "    \n",
    "    def type_from_list(self, item, types):\n",
    "        return item.item_type in types\n",
    "    \n",
    "    def post_mentions_brand(self, post):\n",
    "        \"\"\"\n",
    "        Searches for a match in post's text or external.\n",
    "\n",
    "        Args: \n",
    "            post: a Post object, to search matches in.\n",
    "            \n",
    "        Returns:\n",
    "            bool: true if found a match.\n",
    "        \"\"\"\n",
    "        \n",
    "        text = \"\"\n",
    "        if post.text is not None:\n",
    "            text += post.text\n",
    "        if post.external is not None:\n",
    "            text += ' ' + post.external\n",
    "        return self.brand_regexp.search(text) is not None\n",
    "\n",
    "    def filter_posts_with_brand(self, brand):\n",
    "        \"\"\"\n",
    "        Filters texts with brand mentions.\n",
    "        \n",
    "        Args:\n",
    "            brand (str): name of brand.\n",
    "            \n",
    "        Returns:\n",
    "            generator: filtered posts\n",
    "        \"\"\"\n",
    "        \n",
    "        # regexp matching text not included in html tags.\n",
    "        self.brand_regexp = re.compile(\n",
    "            u'(\\W{brand}\\W)(?![^<]*>|[^<>]*<\\/)'.format(brand=brand), \n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        \n",
    "        return filter(self.post_mentions_brand, self.iterate_all_posts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hn_data = HNData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15361009/15367531 watched | 876 saved\n",
      "last_date: 2017-09-29 00:46:04\n",
      "Counter({'comment': 5644, 'story': 876, 'job': 2})\n"
     ]
    }
   ],
   "source": [
    "hn_data.download_last(start_from_id=15361009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/5727 15361404\n"
     ]
    }
   ],
   "source": [
    "hn_data.add_external_to_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amazon_posts = list(hn_data.filter_posts_with_brand('amazon'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Размер корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazon_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5727"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Источники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_counter = Counter()\n",
    "for post in amazon_posts:\n",
    "    if post.url is not None:\n",
    "        domain = urlparse(post.url).netloc\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "    else: \n",
    "        domain = 'news.ycombinator.com'\n",
    "    domain_counter[domain] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news.ycombinator.com', 16),\n",
       " ('techcrunch.com', 5),\n",
       " ('medium.com', 5),\n",
       " ('blog.clubhouse.io', 4),\n",
       " ('businessinsider.com', 4),\n",
       " ('qz.com', 3),\n",
       " ('vanityfair.com', 3),\n",
       " ('freedom-to-tinker.com', 2),\n",
       " ('geekwire.com', 2),\n",
       " ('wired.co.uk', 2),\n",
       " ('elth.co', 2),\n",
       " ('politico.com', 2),\n",
       " ('aws.amazon.com', 2),\n",
       " ('arstechnica.com', 2),\n",
       " ('longreads.com', 2),\n",
       " ('theguardian.com', 2),\n",
       " ('alanpryorjr.com', 1),\n",
       " ('sfchronicle.com', 1),\n",
       " ('freep.com', 1),\n",
       " ('thenextweb.com', 1)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часто встречающиеся слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_most_common_words(wordlist, num_words=20):\n",
    "    for (word, count) in nltk.FreqDist(wordlist).most_common(num_words):\n",
    "        print (word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_and_join_texts(posts):\n",
    "    res = \"\"\n",
    "    for post in posts:\n",
    "        if post.text is not None:\n",
    "            res += ' ' + post.text\n",
    "        if post.external is not None:\n",
    "            res += ' ' + post.external\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_texts = extract_and_join_texts(amazon_posts)\n",
    "# extract words from texts (ignoring text in tags)\n",
    "wordlist = re.findall(u'([a-z][a-z\\-’]+[a-z])(?![^<]*>|[^<>]*<\\/)', joined_texts.lower())\n",
    "wordlist_clear = [token for token in wordlist if not token in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freebsd 199\n",
      "amazon 184\n",
      "sha 163\n",
      "also 124\n",
      "one 97\n",
      "data 95\n",
      "iso 87\n",
      "like 79\n",
      "company 75\n",
      "time 72\n",
      "google 69\n",
      "new 65\n",
      "img 65\n",
      "use 63\n",
      "get 61\n",
      "would 61\n",
      "using 56\n",
      "make 54\n",
      "available 54\n",
      "com 52\n",
      "release-amd 51\n",
      "people 47\n",
      "email 47\n",
      "could 46\n",
      "well 46\n",
      "first 44\n",
      "used 44\n",
      "quot 44\n",
      "said 44\n",
      "may 43\n"
     ]
    }
   ],
   "source": [
    "print_most_common_words(wordlist_clear, num_words=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>f-', ' f-', ' f.', ' f.', ' f.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(u'(\\Wc\\W)(?![^<]*>|[^<>]*<\\/)', joined_texts.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Nicolas Armer\\/picture-alliance\\/dpa\\/AP Images&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;ARCHIV - Eine Kursteilnehmerin ist a\n"
     ]
    }
   ],
   "source": [
    "ind = joined_texts.lower().find('quot', ind + 1)\n",
    "print(joined_texts[ind - 100:ind + 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
